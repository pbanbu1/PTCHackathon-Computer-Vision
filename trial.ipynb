{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.3\n2.4.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.applications import VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import os, shutil\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import seaborn\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(conv_base, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir_rust = 'RustPhotos2'\n",
    "original_dataset_dir_norust = 'norust'\n",
    "\n",
    "#dir to store images\n",
    "store_directory = 'ttv_images'\n",
    "train_dir = os.path.join(store_directory, 'train')\n",
    "validation_dir = os.path.join(store_directory, 'validation')\n",
    "test_dir = os.path.join(store_directory, 'test')\n",
    "\n",
    "rust_train = os.path.join(train_dir, 'rust')\n",
    "norust_train = os.path.join(train_dir, 'norust')\n",
    "\n",
    "norust_validation = os.path.join(validation_dir, 'norust')\n",
    "rust_validation = os.path.join(validation_dir, 'rust')\n",
    "\n",
    "rust_test = os.path.join(test_dir, 'rust')\n",
    "norust_test = os.path.join(test_dir, 'norust')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##runs a single time\n",
    "os.mkdir(store_directory)\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "os.mkdir(test_dir)\n",
    "os.mkdir(rust_train)\n",
    "os.mkdir(norust_train)\n",
    "os.mkdir(rust_validation)\n",
    "os.mkdir(norust_validation)\n",
    "os.mkdir(rust_test)\n",
    "os.mkdir(norust_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "fnames =  os.listdir(original_dataset_dir_norust)\n",
    "print(len(fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #copies first 75 images to train \n",
    "filenames =  os.listdir(original_dataset_dir_rust)\n",
    "# for i in range(0, 70):\n",
    "#     src = os.path.join(original_dataset_dir_rust, filenames[i])\n",
    "#     dst = os.path.join(rust_train, filenames[i])\n",
    "#     shutil.copyfile(src, dst)\n",
    "\n",
    "# #copies first 5 images to train \n",
    "\n",
    "for i in range(69, 75):\n",
    "    src = os.path.join(original_dataset_dir_rust, filenames[i])\n",
    "    dst = os.path.join(rust_validation, filenames[i])\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#copies first 5 images to train \n",
    "for i in range(70, 79):\n",
    "    src = os.path.join(original_dataset_dir_rust, filenames[i])\n",
    "    dst = os.path.join(rust_test, filenames[i])\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "filenames =  os.listdir(original_dataset_dir_norust)\n",
    "# for i in range(0, 60 ):\n",
    "#     src = os.path.join(original_dataset_dir_norust, filenames[i])\n",
    "#     dst = os.path.join(norust_train, filenames[i])\n",
    "#     shutil.copyfile(src, dst)\n",
    "\n",
    "for i in range(61, 67 ):\n",
    "    src = os.path.join(original_dataset_dir_norust, filenames[i])\n",
    "    dst = os.path.join(norust_validation, filenames[i])\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "for i in range(63, 71 ):\n",
    "    src = os.path.join(original_dataset_dir_norust, filenames[i])\n",
    "    dst = os.path.join(norust_test, filenames[i])\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 4, 4, 512)         14714688  \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               2097408   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 16,812,353\nTrainable params: 16,812,353\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "conv_base.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 130 images belonging to 2 classes.\nFound 12 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'ttv_images'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 - 29s - loss: 0.6089 - acc: 0.7250 - val_loss: 0.5247 - val_acc: 0.8333\n",
      "Epoch 2/15\n",
      "10/10 - 12s - loss: 0.5054 - acc: 0.8750\n",
      "Epoch 3/15\n",
      "10/10 - 13s - loss: 0.4707 - acc: 0.8500\n",
      "Epoch 4/15\n",
      "10/10 - 12s - loss: 0.4187 - acc: 0.8500\n",
      "Epoch 5/15\n",
      "10/10 - 10s - loss: 0.3605 - acc: 0.9474\n",
      "Epoch 6/15\n",
      "10/10 - 12s - loss: 0.3741 - acc: 0.8684\n",
      "Epoch 7/15\n",
      "10/10 - 11s - loss: 0.2446 - acc: 0.9500\n",
      "Epoch 8/15\n",
      "10/10 - 11s - loss: 0.2895 - acc: 0.9211\n",
      "Epoch 9/15\n",
      "10/10 - 11s - loss: 0.3716 - acc: 0.8421\n",
      "Epoch 10/15\n",
      "10/10 - 13s - loss: 0.2101 - acc: 1.0000\n",
      "Epoch 11/15\n",
      "10/10 - 9s - loss: 0.3324 - acc: 0.8500\n",
      "Epoch 12/15\n",
      "10/10 - 13s - loss: 0.3043 - acc: 0.8750\n",
      "Epoch 13/15\n",
      "10/10 - 13s - loss: 0.3508 - acc: 0.8500\n",
      "Epoch 14/15\n",
      "10/10 - 11s - loss: 0.2724 - acc: 0.9211\n",
      "Epoch 15/15\n",
      "10/10 - 12s - loss: 0.2326 - acc: 0.9250\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir='/output/{}'.format(time()))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['acc'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=10,epochs=15,validation_data=validation_generator,validation_steps=20,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 17 images belonging to 2 classes.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "test acc: 0.7058823704719543\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=4,\n",
    "        shuffle=False, \n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=10)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8 images belonging to 2 classes.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      norust       1.00      0.50      0.67         4\n",
      "        rust       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.83      0.75      0.73         8\n",
      "weighted avg       0.83      0.75      0.73         8\n",
      "\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=4,\n",
    "        shuffle=False, # v imp : do not shuffle in case of test data, when measuring precision and recall\n",
    "        class_mode='binary')\n",
    "\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "\n",
    "val_preds = np.zeros((predictions.shape[0],1))\n",
    "for i in range(predictions.shape[0]):\n",
    "    if predictions[i]>0.5:\n",
    "        val_preds[i] = 1\n",
    "    else:\n",
    "        val_preds[i] = 0\n",
    "val_trues = test_data_generator.classes\n",
    "\n",
    "labels = test_data_generator.class_indices.keys()\n",
    "\n",
    "report = classification_report(val_trues, val_preds, target_names=labels)\n",
    "print(report) \n",
    "print(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}